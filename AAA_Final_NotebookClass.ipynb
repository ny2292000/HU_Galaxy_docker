{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb0543-99aa-43eb-ac22-079f47ac959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "class NotebookProcessor:\n",
    "    def __init__(self, notebook_path):\n",
    "        self.notebook_path = notebook_path\n",
    "        self.notebook_data = None\n",
    "        self.urls = []\n",
    "        self.downloaded_files = []  # Track downloaded files\n",
    "        self.load_notebook()\n",
    "\n",
    "    def load_notebook(self):\n",
    "        \"\"\"Loads the notebook content into memory.\"\"\"\n",
    "        with open(self.notebook_path, 'r') as file:\n",
    "            self.notebook_data = json.load(file)\n",
    "\n",
    "    def save_notebook(self, save_path=None):\n",
    "        \"\"\"Saves the notebook content from memory back to file.\"\"\"\n",
    "        if save_path is None:\n",
    "            save_path = self.notebook_path\n",
    "        with open(save_path, 'w') as file:\n",
    "            json.dump(self.notebook_data, file, indent=2)\n",
    "        \n",
    "    def clean_downloaded_files(self):\n",
    "        # Delete downloaded files\n",
    "        for file_path in self.downloaded_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Successfully deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")\n",
    "\n",
    "    \n",
    "    def clean(self, directories_to_clean=[]):\n",
    "        \"\"\"Cleans all outputs from code cells in the notebook, deletes downloaded files, and clears specified directories.\"\"\"\n",
    "        if self.notebook_data is None:\n",
    "            print(\"Notebook data is not loaded.\")\n",
    "            return self\n",
    "\n",
    "        # Clean code cell outputs\n",
    "        for cell in self.notebook_data['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                cell['outputs'] = []\n",
    "                cell['execution_count'] = None\n",
    "        \n",
    "        self.clean_downloaded_files()\n",
    "        \n",
    "        # Clear specified directories\n",
    "        for directory in directories_to_clean:\n",
    "            if os.path.exists(directory):\n",
    "                for filename in os.listdir(directory):\n",
    "                    file_path = os.path.join(directory, filename)\n",
    "                    try:\n",
    "                        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                            os.unlink(file_path)\n",
    "                        elif os.path.isdir(file_path):\n",
    "                            shutil.rmtree(file_path)\n",
    "                        print(f\"Removed: {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "        \n",
    "        self.save_notebook()\n",
    "\n",
    "    def download_files(self, urls, directory):\n",
    "        self.urls = urls\n",
    "        \"\"\"Downloads files from the given URLs into the specified directory.\"\"\"\n",
    "        os.makedirs(directory, exist_ok=True)  # Ensure the directory exists\n",
    "        downloaded_files = []\n",
    "        for url in self.urls:\n",
    "            try:\n",
    "                local_filename = url.split('/')[-1]  # Extract the file name from the URL\n",
    "                local_filepath = os.path.join(directory, local_filename)  # Full local path\n",
    "                downloaded_files.append(local_filepath)\n",
    "                with requests.get(url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(local_filepath, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "                self.downloaded_files.append(local_filepath)  # Track downloaded file\n",
    "                print(f\"Downloaded and saved: {local_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {url}: {e}\")\n",
    "        self.download_files= downloaded_files\n",
    "\n",
    "    def export_to_py(self, output_path):\n",
    "        \"\"\"Exports notebook code cells to a Python (.py) file.\"\"\"\n",
    "        with open(output_path, 'w') as py_file:\n",
    "            for cell in self.notebook_data['cells']:\n",
    "                if cell['cell_type'] == 'code':\n",
    "                    py_file.write(''.join(cell['source']) + '\\n\\n')\n",
    "        print(f\"Python file created at: {output_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def find_notebooks(directory):\n",
    "        \"\"\"Recursively finds all notebooks in a directory.\"\"\"\n",
    "        notebooks = []\n",
    "        for root, _, filenames in os.walk(directory):\n",
    "            for filename in fnmatch.filter(filenames, '*.ipynb'):\n",
    "                notebooks.append(os.path.join(root, filename))\n",
    "        return notebooks\n",
    "\n",
    "    @staticmethod\n",
    "    def cell_similarity(cell_a, cell_b):\n",
    "        \"\"\"Calculates the similarity of two cells using a simple ratio.\"\"\"\n",
    "        return SequenceMatcher(None, cell_a, cell_b).ratio()\n",
    "\n",
    "    @classmethod\n",
    "    def compare_notebooks(cls, notebook_path_a, notebook_path_b):\n",
    "        \"\"\"Compares two notebooks and returns the similarity metrics.\"\"\"\n",
    "        with open(notebook_path_a, 'r') as file_a, open(notebook_path_b, 'r') as file_b:\n",
    "            notebook_a = json.load(file_a)\n",
    "            notebook_b = json.load(file_b)\n",
    "        \n",
    "        identical, similar, distinct = 0, 0, 0\n",
    "        for cell_a in notebook_a['cells']:\n",
    "            if cell_a['cell_type'] == 'code':\n",
    "                for cell_b in notebook_b['cells']:\n",
    "                    if cell_b['cell_type'] == 'code':\n",
    "                        similarity = cls.cell_similarity(''.join(cell_a['source']), ''.join(cell_b['source']))\n",
    "                        if similarity == 1:\n",
    "                            identical += 1\n",
    "                        elif similarity >= 0.6:  # Threshold for \"similarity\"\n",
    "                            similar += 1\n",
    "                        else:\n",
    "                            distinct += 1\n",
    "        return identical, similar, distinct\n",
    "\n",
    "    # @staticmethod\n",
    "    # def find_notebooks(directory):\n",
    "    #     \"\"\"Recursively finds all notebook files in the specified directory, excluding '.ipynb_checkpoints'.\"\"\"\n",
    "    #     notebooks = []\n",
    "    #     for root, dirs, files in os.walk(directory):\n",
    "    #         # Skip any directories named '.ipynb_checkpoints'\n",
    "    #         dirs[:] = [d for d in dirs if d != '.ipynb_checkpoints']\n",
    "    #         for file in files:\n",
    "    #             if file.endswith(\".ipynb\"):\n",
    "    #                 notebooks.append(os.path.join(root, file))\n",
    "    #     return notebooks\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_notebooks(directory):\n",
    "        \"\"\"Finds all notebook files in the specified directory, excluding '.ipynb_checkpoints', without recursing into subdirectories.\"\"\"\n",
    "        notebooks = []\n",
    "        # Ensure not to consider '.ipynb_checkpoints' by filtering directories\n",
    "        for file in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, file)\n",
    "            if file.endswith(\".ipynb\") and '.ipynb_checkpoints' not in filepath:\n",
    "                notebooks.append(filepath)\n",
    "        return notebooks\n",
    "\n",
    "    @classmethod\n",
    "    def compare_notebooks(cls, notebook_path_a, notebook_path_b):\n",
    "        \"\"\"Compares two notebooks based on their code cells content.\"\"\"\n",
    "        # Load notebooks\n",
    "        with open(notebook_path_a, 'r', encoding='utf-8') as file_a:\n",
    "            notebook_a = json.load(file_a)\n",
    "        with open(notebook_path_b, 'r', encoding='utf-8') as file_b:\n",
    "            notebook_b = json.load(file_b)\n",
    "        \n",
    "        # Initialize counts\n",
    "        identical, similar, distinct = 0, 0, 0\n",
    "        \n",
    "        # Extract and compare code cells\n",
    "        code_cells_a = [cell['source'] for cell in notebook_a['cells'] if cell['cell_type'] == 'code']\n",
    "        code_cells_b = [cell['source'] for cell in notebook_b['cells'] if cell['cell_type'] == 'code']\n",
    "        \n",
    "        # Prepare for comparison\n",
    "        for cell_a in code_cells_a:\n",
    "            cell_a_content = ''.join(cell_a).strip()\n",
    "            if not cell_a_content:  # Skip empty cells\n",
    "                continue\n",
    "            best_match = 0  # Track the best match for this cell\n",
    "            for cell_b in code_cells_b:\n",
    "                cell_b_content = ''.join(cell_b).strip()\n",
    "                if not cell_b_content:  # Skip empty cells\n",
    "                    continue\n",
    "                similarity = SequenceMatcher(None, cell_a_content, cell_b_content).ratio()\n",
    "                if similarity > best_match:\n",
    "                    best_match = similarity\n",
    "            if best_match == 1:\n",
    "                identical += 1\n",
    "            elif best_match > 0:\n",
    "                similar += 1\n",
    "            else:\n",
    "                distinct += 1\n",
    "        \n",
    "        if notebook_path_a == notebook_path_b:\n",
    "            # Adjust counts for self-comparison to consider non-empty cells only\n",
    "            non_empty_cells = sum(1 for cell in code_cells_a if ''.join(cell).strip())\n",
    "            identical = non_empty_cells\n",
    "            similar = 0\n",
    "            distinct = 0\n",
    "        \n",
    "        return identical, similar, distinct\n",
    "\n",
    "    @classmethod\n",
    "    def generate_comparison_matrix(cls, directory):\n",
    "        notebooks = cls.find_notebooks(directory)\n",
    "        comparison_results = []\n",
    "\n",
    "        for i, notebook_a in enumerate(notebooks):\n",
    "            for notebook_b in notebooks[i+1:]:\n",
    "                identical, similar, distinct = cls.compare_notebooks(notebook_a, notebook_b)\n",
    "                comparison_results.append((notebook_a, notebook_b, identical, similar, distinct))\n",
    "        \n",
    "        return comparison_results\n",
    "\n",
    "    @classmethod\n",
    "    def save_comparisons_to_txt(cls, comparison_results, output_path):\n",
    "        \"\"\"Saves the comparison results to a text file.\"\"\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            for result in comparison_results:\n",
    "                f.write(f\"{result[0]}, {result[1]}, Identical: {result[2]}, Similar: {result[3]}, Distinct: {result[4]}\\n\")\n",
    "\n",
    "    @classmethod\n",
    "    def save_comparisons_to_excel(cls, comparison_results, output_path):\n",
    "        \"\"\"Saves the comparison results to an Excel file.\"\"\"\n",
    "        # Create a DataFrame from the comparison results\n",
    "        df = pd.DataFrame(comparison_results, columns=['Notebook 1', 'Notebook 2', 'Identical Cells', 'Similar Cells', 'Distinct Cells'])\n",
    "        \n",
    "        # Save the DataFrame to an Excel file\n",
    "        df.to_excel(output_path, index=False)\n",
    "        print(f\"Comparison results saved to {output_path}\")\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def generate_graph(cls, comparison_results, similarity_threshold):\n",
    "        \"\"\"Generates and displays a graph based on the comparison results and a similarity threshold.\"\"\"\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add edges for notebook pairs that meet the similarity threshold\n",
    "        for nb1, nb2, identical, similar, distinct in comparison_results:\n",
    "            if identical + similar >= similarity_threshold:\n",
    "                G.add_node(nb1, label=os.path.basename(nb1))\n",
    "                G.add_node(nb2, label=os.path.basename(nb2))\n",
    "                G.add_edge(nb1, nb2, weight=identical + similar)\n",
    "\n",
    "        # Draw the graph\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=20)\n",
    "        nx.draw(G, pos, with_labels=True, node_size=2000, node_color=\"skyblue\", font_size=10, font_weight=\"bold\")\n",
    "        edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07f561-d939-49a4-af2f-183fada7cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__==\"__main__\":\n",
    "dirs = [\"./img\", \"./img1\", \"./universeorthoviewdual\", \"./universeorthoview_48_48\", \"./PG_data\", \"./universeorthoview\"]\n",
    "# Directory to which we want to save the files\n",
    "directory = './DataSupernovaLBLgov'\n",
    "# URLs of the files to download\n",
    "urls = [\n",
    "    'https://irsa.ipac.caltech.edu/data/Planck/release_3/ancillary-data/cosmoparams/COM_PowerSpect_CMB-base-plikHM-TTTEEE-lowl-lowE-lensing-minimum-theory_R3.01.txt',\n",
    "    'https://irsa.ipac.caltech.edu/data/Planck/release_2/all-sky-maps/maps/component-maps/cmb/COM_CMB_IQU-smica_1024_R2.02_full.fits'\n",
    "]\n",
    "# notebook1 = NotebookProcessor(\"./AAAA1_AWS_UniverseMap-GoldenCopy.ipynb\")\n",
    "# notebook1.download_files(urls=urls, directory=directory)\n",
    "# notebook1.clean_downloaded_files()\n",
    "# notebook1.clean(directories_to_clean=dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba7016-9c97-4cb1-b982-74ae2baf9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook1 = NotebookProcessor(\"./AAA_Final_CMB_Modeling_UniverseMap.ipynb\")\n",
    "# notebook1.export_to_py(\"./AAA_Final_CMB_Modeling_UniverseMap.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72d7a6-8bcc-492c-887c-f5a0eb880534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "directory = './'\n",
    "# Assuming the generate_comparison_matrix and other necessary methods are defined within the class\n",
    "comparison_results = NotebookProcessor.generate_comparison_matrix(directory)\n",
    "# NotebookProcessor.save_comparisons_to_txt(comparison_results, output_path)\n",
    "# NotebookProcessor.generate_graph(comparison_results, similarity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13e21b-83b0-4071-b579-791845d94f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_txt = './comparison_results.txt'\n",
    "NotebookProcessor.save_comparisons_to_txt(comparison_results, output_path_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5beeeb4-0e07-4715-a0ae-b91fa61781e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_xls = './comparison_results.xlsx'\n",
    "NotebookProcessor.save_comparisons_to_excel(comparison_results, output_path_xls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50203cb-2ae8-40f4-a462-c31cc1e95ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 115  # Define a threshold for similarity\n",
    "NotebookProcessor.generate_graph(comparison_results, similarity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baeabff-19a0-4d2b-807f-761ad7e84546",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"./AAAA1_AWS_UniverseMap-GoldenCopy.ipynb\"\n",
    "identical, similar, distinct = NotebookProcessor.compare_notebooks(notebook_path, notebook_path)\n",
    "\n",
    "print(f\"Identical: {identical}, Similar: {similar}, Distinct: {distinct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa6178-c07b-45f6-b8be-f40452ed0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook1.export_to_py(\"./CMB_HU_latest_to_git.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3849dd4-4cc0-4c23-8faf-73d192846766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming compare_notebooks returns similarity score and we have a list of tuples: (notebook1, notebook2, similarity_score)\n",
    "# Example: [('nb1.ipynb', 'nb2.ipynb', 5), ...]\n",
    "directory = './'\n",
    "comparison_results = NotebookProcessor.generate_comparison_matrix(directory)\n",
    "# print(comparison_results)\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges between notebooks with weights based on similarity\n",
    "for nb1, nb2, similarity,s2,s3 in comparison_results:\n",
    "    if similarity > 0:  # Assuming we only care about notebooks with some similarity\n",
    "        G.add_edge(nb1, nb2, weight=similarity)\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.spring_layout(G)  # Positions for all nodes\n",
    "\n",
    "# Nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "\n",
    "# Edges\n",
    "weights = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edges(G, pos, width=list(weights.values()))\n",
    "\n",
    "# Labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c032a68-aa9a-4e47-b3a8-8a652df33b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c035f84-a70d-41c0-8242-37ae2e1e114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "def print_first_cells(notebook_path, num_cells=3):\n",
    "    \"\"\"Print the source of the first few code cells in the notebook.\"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "        code_cells = [cell for cell in nb.cells if cell.cell_type == 'code']\n",
    "        for cell in code_cells[:num_cells]:\n",
    "            print(''.join(cell.source))\n",
    "            print('---')  # Separator\n",
    "\n",
    "# Example usage:\n",
    "print_first_cells('./AAAA1_AWS_UniverseMap-GoldenCopy.ipynb',10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb57fb0-fc3a-4bfc-8e9c-8188d19a5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_specific_cells(notebook_path_a, notebook_path_b, cell_index):\n",
    "    \"\"\"Compare the source of a specific cell index between two notebooks.\"\"\"\n",
    "    with open(notebook_path_a, 'r', encoding='utf-8') as f:\n",
    "        nb_a = nbformat.read(f, as_version=4)\n",
    "    with open(notebook_path_b, 'r', encoding='utf-8') as f:\n",
    "        nb_b = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    cell_a = nb_a.cells[cell_index].source if cell_index < len(nb_a.cells) else \"Cell index out of range\"\n",
    "    cell_b = nb_b.cells[cell_index].source if cell_index < len(nb_b.cells) else \"Cell index out of range\"\n",
    "\n",
    "    # Print both cells for manual comparison\n",
    "    print(\"Notebook A cell content:\")\n",
    "    print(cell_a)\n",
    "    print(\"\\nNotebook B cell content:\")\n",
    "    print(cell_b)\n",
    "\n",
    "# Example usage:\n",
    "compare_specific_cells('./AAAA_qutip_A.ipynb', './AAAA1_AWS_UniverseMap-GoldenCopy.ipynb', 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0eca7-98d1-4835-aac8-886d1986a4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Cosmos3020]",
   "language": "python",
   "name": "conda-env-Cosmos3020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
